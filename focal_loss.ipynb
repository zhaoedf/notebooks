{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "C = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2535, 0.5691, 0.5391, 0.4035, 0.9875],\n",
       "        [0.9943, 0.6627, 0.6124, 0.3754, 0.1337],\n",
       "        [0.6902, 0.9178, 0.7491, 0.6236, 0.6748],\n",
       "        [0.3196, 0.9011, 0.0685, 0.7702, 0.8129],\n",
       "        [0.9854, 0.6996, 0.9426, 0.9156, 0.6943],\n",
       "        [0.3129, 0.1314, 0.3183, 0.7093, 0.7391],\n",
       "        [0.6043, 0.5104, 0.6273, 0.3179, 0.6112],\n",
       "        [0.1817, 0.1793, 0.2405, 0.0728, 0.8850],\n",
       "        [0.1469, 0.1037, 0.0426, 0.2138, 0.5344],\n",
       "        [0.1279, 0.6379, 0.3452, 0.2874, 0.8062],\n",
       "        [0.3860, 0.8059, 0.5053, 0.4707, 0.8393],\n",
       "        [0.0996, 0.6392, 0.3099, 0.4323, 0.1879],\n",
       "        [0.0845, 0.9669, 0.9097, 0.3467, 0.9879],\n",
       "        [0.1883, 0.6860, 0.5933, 0.8607, 0.2761],\n",
       "        [0.2217, 0.9066, 0.8370, 0.0201, 0.6622],\n",
       "        [0.5075, 0.5571, 0.3007, 0.2858, 0.0426]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.rand(N,C)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 3, 2, 3, 0, 2, 1, 0, 0, 4, 0, 2, 2, 4, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(0,C,(N,))\n",
    "# target = F.one_hot(target,num_classes=5)\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self_defined focal loss(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_loss(nn.Module):\n",
    "    def __init__(self, alpha:torch.Tensor, gamma:float,reduction='none'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self,pred:torch.Tensor, target:torch.Tensor):\n",
    "        log_softmax = nn.LogSoftmax(dim=1) # dim=-1 is the same\n",
    "        log_softmax_pred = log_softmax(pred)\n",
    "        pred_softmax = log_softmax_pred.exp()\n",
    "        \n",
    "        # weight的元素数目必须要和class_num的一致，不能只给出一个数字，torch在这里不会自动“广播”\n",
    "        nll_loss = nn.NLLLoss(weight=self.alpha, reduction='none') \n",
    "        ce_loss = nll_loss(log_softmax_pred,target)\n",
    "        \n",
    "        rows = torch.arange(pred.shape[0]) \n",
    "        pt = pred_softmax[rows,target]\n",
    "        focal_weight = (1-pt).pow(self.gamma)\n",
    "        \n",
    "        # NLL_Loss计算中已经带有负号，所以这里就不加负号了！\n",
    "        # 见OneNote易懂。\n",
    "        loss = focal_weight*ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        elif self.reduction == 'sum': return loss.sum()\n",
    "        else: return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = focal_loss(torch.tensor([0.2]*5),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2091, 0.1910, 0.2324, 0.3391, 0.1922, 0.2431, 0.1862, 0.2485, 0.2240,\n",
       "        0.2877, 0.1565, 0.2657, 0.1639, 0.1966, 0.1888, 0.2221])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_result = fl(pred,target)\n",
    "my_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## github focal loss(classification) <br>\n",
    "https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py#L36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\" Focal Loss, as described in https://arxiv.org/abs/1708.02002.\n",
    "    It is essentially an enhancement to cross entropy loss and is\n",
    "    useful for classification tasks when there is a large class imbalance.\n",
    "    x is expected to contain raw, unnormalized scores for each class.\n",
    "    y is expected to contain class labels.\n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 alpha: None,\n",
    "                 gamma: float = 0.,\n",
    "                 reduction: str = 'mean',\n",
    "                 ignore_index: int = -100):\n",
    "\n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(\n",
    "                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(\n",
    "            weight=alpha, reduction='none', ignore_index=ignore_index)\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_keys = ['alpha', 'gamma', 'ignore_index', 'reduction']\n",
    "        arg_vals = [self.__dict__[k] for k in arg_keys]\n",
    "        arg_strs = [f'{k}={v}' for k, v in zip(arg_keys, arg_vals)]\n",
    "        arg_str = ', '.join(arg_strs)\n",
    "        return f'{type(self).__name__}({arg_str})'\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim > 2:\n",
    "            # x:(N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            c = x.shape[1]\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            # y:(N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "            y = y.view(-1)\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt)\n",
    "        # (alpha is already part of self.nll_loss, if you provide the weight parameter of sefl.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row (row stants for one sample in a batch)\n",
    "        all_rows = torch.arange(len(x))\n",
    "        log_pt = log_p[all_rows, y]  \n",
    "        '''\n",
    "            ①log_pt 是一个matrix(因为x permute之后变为2维，而log_p来自x，log_softmax和nll_loss都不改变输入的shape)\n",
    "            ②multi-class ✔  multi-label ×\n",
    "            ③从这里取log_pt的方式可以看出，从二分类扩展focal loss到多分类之后，*因为GT是one-hot编码的*，\n",
    "            所以只是把原来二分类的从两个类别中取pt计算，变为了从多个类中取pt计算，具体而言就是pt矩阵的某一维从2变为C而已！\n",
    "            所以多分类focal loss很容易理解！\n",
    "        '''\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        '''\n",
    "            不同于二分类，因为在多分类中，没有所谓的背景(除非显示定义)，所以直接1-pred就好了。\n",
    "            而二分类则是(GT-pred)，因为二分类中,GT==1:pt=1 ; GT==0:pt=1-pred\n",
    "        '''\n",
    "        focal_term = (1 - pt)**self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_github = FocalLoss(torch.tensor([0.2]*5),2,reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2091, 0.1910, 0.2324, 0.3391, 0.1922, 0.2431, 0.1862, 0.2485, 0.2240,\n",
       "        0.2877, 0.1565, 0.2657, 0.1639, 0.1966, 0.1888, 0.2221])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_result = fl_github(pred,target)\n",
    "github_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_result == github_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seg-focal-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二分类\n",
    "class Focal_loss(nn.Module):\n",
    "    def __init__(self,pow=1):\n",
    "        super(Focal_loss,self).__init__()\n",
    "        self.power = pow\n",
    "\n",
    "    def forward(self,pred,true):\n",
    "        b,c,w,h= pred.size()\n",
    "        p = pred.view(b, -1)\n",
    "        t = true.view(b, -1)\n",
    "        eps = 1e-6\n",
    "        #原来的写法\n",
    "        #loss = t*(1 - p).pow(self.power)*p.log()\n",
    "        #改为下面这句，就和我的计算结果一样了(大部分小数一样，就认为是一样了 nm)。\n",
    "        # 两个写法等价：\n",
    "        #--------------------①\n",
    "#         loss1 = t*(1-p).pow(self.power)*p.log()\n",
    "#         loss2 = (1-t)*p.pow(self.power)*(1-p).log()  #p.pow == (1-(1-p)).pow\n",
    "#         loss = (loss1+loss2).sum(1)/(w*h)\n",
    "        #--------------------②\n",
    "        loss = ((t-p).pow(2)*torch.log(((1-t)-p).abs()+eps)).sum(1)/(w*h)\n",
    "        loss = -loss.mean(0)\n",
    "        return loss\n",
    "    \n",
    "# 多分类\n",
    "#TO check\n",
    "class Focal_loss_multi_class(nn.Module):\n",
    "    def __init__(self,device,pow=2):\n",
    "        super(Focal_loss_multi_class,self).__init__()\n",
    "        self.power = pow\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,probs,true):\n",
    "        num_classes = probs.shape[1]\n",
    "        #pred = probs > 0.5\n",
    "        \n",
    "        classes_points = []\n",
    "        for i in range(num_classes):\n",
    "            classes_points.append(probs[:,i]>0.5)\n",
    "\n",
    "        loss_focal = torch.zeros((num_classes,),dtype=torch.float32).to(self.device)\n",
    "        for i in range(num_classes):\n",
    "            loss_focal[i] = (classes_points[i]*(1-probs[:,i]).pow(2)*probs[:,i].log()).mean()\n",
    "\n",
    "\n",
    "        loss_focal = -loss_focal.sum()\n",
    "        return loss_focal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改前的Focal loss是github上找的。<br>\n",
    "它的计算方式是错误的，因为它的计算方法为 t*(1-p).pow(self.power)，<br>\n",
    "因为这个“t*”的存在，所以最终体现“难例挖掘”的\"(1-p).pow(self.power)\"只会含有正样本，<br>\n",
    "而根据原论文的意思(由pt的定义易懂)，难例可以是正样本，也可以是负样本，所以这里的写法是错误的！<br>\n",
    "<br>\n",
    "并且，同时也要修改p.log()，因为此时对于正样本是p.log(),对于负样本则是(1-p).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.randn((8,1,512,512),dtype=torch.float)\n",
    "probs = torch.sigmoid(out)\n",
    "true_mask = torch.randint(0,2,(8,1,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]), tensor([0.4765]), tensor([0.6169]))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mask[0,...,0,0],out[0,...,0,0],probs[0,...,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 tensor([-0.3471, -0.3457, -0.3456, -0.3461, -0.3454, -0.3459, -0.3471, -0.3461])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3461)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdaa = 1.0\n",
    "# loss_focal_batch = ((((true_mask-probs)**2)*torch.log(probs)).mean(axis=(1,2,3))) * lambdaa\n",
    "loss1 = (true_mask*(1-probs)**2)*torch.log(probs)\n",
    "loss2 = (1-true_mask)*(probs**2)*torch.log(1-probs)\n",
    "loss_focal_batch = (loss1+loss2).mean(axis=(1,2,3)) * lambdaa\n",
    "print(len(loss_focal_batch),loss_focal_batch)\n",
    "loss_focal = -loss_focal_batch.mean()\n",
    "loss_focal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上这个计算结果是GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Focal_loss(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3461)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(probs,true_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过多次计算，发现两个focal_loss输出值的差值不会＞0.0004，所以可以认为两者一样！<br>\n",
    "总结起来就是，二分类focal_loss的核心公式为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = (true_mask*(1-probs)**2)*torch.log(probs)\n",
    "loss2 = (1-true_mask)*(probs**2)*torch.log(1-probs)\n",
    "loss_focal_batch = (loss1+loss2).mean(axis=(1,2,3)) * lambdaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类focal loss<br>\n",
    "沿用上面的数据probs和true_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlfl1 = Focal_loss_multi_class(device,2)\n",
    "a = torch.sigmoid(torch.randint(-20,200,(3,4,8,8)).to(torch.float))\n",
    "true = torch.randint(0,4,(3,4,8,8))\n",
    "out1 = mlfl1(a,true)\n",
    "out1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
